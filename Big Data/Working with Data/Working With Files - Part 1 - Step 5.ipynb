{"cells":[{"cell_type":"markdown","source":["Copyright Scott Jensen, San Jose State University\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">This notebook</span> by <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Scott Jensen,Ph.D.</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14693142-6922-4fd2-a4fa-3a3743e40341"}}},{"cell_type":"markdown","source":["# Working With Files Part 1: Loading The Yelp Data\n\n**<span style=\"color:red\">This version of the notebook includes only Steps 2, 3, and 5 of Part 1 which loads the Yelp data.</span>** This version of Step 5 should be run if you have already completed Parts 2 and 3 in the original version of the notebook.\n\nWhen running this notebook, first complete steps 2 & 3 to create the widget for the manifest URL and add that URL to the widget before running step 5.\n\nAfter running this notebook, Return to your original notebook and complete the three code cells in steps 6 and 7 of Part 1 before submitting your notebook for grading."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62ee669e-03c8-48a4-b5fc-c4636f04056c"}}},{"cell_type":"markdown","source":["### Step 2: Using a Databricks widget to enter the path to the data manifest\n\nSince some of the data files are too large to manually upload even when compressed, you will be importing the data from where we temporarily staged it on AWS, but **you *MUST* complete the dataset agreement assignment in order to earn credit for *ANY* of the exercises or the team assignments which use the Yelp data**.  To bring the data from where we staged it on AWS to your Databricks account hosted on AWS (for free by Databricks! Yay!) the code below needs to know where it can downlaod the data from.\n\nWhen you run the next cell, a \"widget\" will appear **at the top of the notebook** that prompts you for your the path to a data manifest.  \nOn the right-hand side of that widget bar you will see a pushpin (a.k.a. thumbtack) icon that will allow you to pin that to the top of the code window even when you scroll down.  Once you have entered the manifest's path, you can \"unpin\" the widget bar to make more screen real estate available.\n\nWe will be importing three files to your Databricks account and eventually we will be putting the compressed files they contain in a directory named `/yelp` on the Databricks File System (DBFS) on your Databricks account. The manifest uses a JSON format and contains a JSON array with an object for each file.  Each JSON object provides three properties: the name of the file, an MD5 sum for the file, and a flag as to whether the file should be unzipped. The MD5 sum is a one-way hash that allows us to make sure the file download did not encounter any errors and is exactly the same as the file we originally staged on AWS.  The flag for whether to unzip is because we compress the data flies using the bzip2 format, but the review and user data files have been split by year (the year of the review or the year a user joined Yelp), so we zipped up the directories containing those files.  We need to unzip those directories before moving the files to the `/yelp` irectory on DBFS. You may be wondering why the manifest file is used, but it allows us to easily move the files or update them, and we only need to provide you with the URL to where you can find the current manifest.\n\nTo see the widget (if you just imported the notebook), click on the arrow in the upper \nright-hand corner of the next code cell and select `Run Cell`.\n\n#### The following cell is Step 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"50f8c16a-44d2-4698-abc0-bdfad64a49c3"}}},{"cell_type":"code","source":["dbutils.widgets.text(\"manifest_url\",\"xxxxxxxxxxxxxxx\",\"Enter the manifest URL:\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba7c79b4-5db5-4afc-b0cf-780bb1e9df9b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Step 3: Entering the file manifest URL\n\nIn the input box for the widget with the prompt \"Enter the manifest URL\", enter the URL we provide in class.\n\nOnce you have entered the URL in the widget, we can get started."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14e680d6-5e6e-468e-8893-9d8d6ae9abc3"}}},{"cell_type":"code","source":["dbutils.fs.help()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"915f6b57-d204-4a85-8557-50c0560cbac9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Step 5: Importing the data\n\nThe code in the following cell will import the data files to your yelp directory.  While that cell is running (**it will probably take around 5 minutes**), let's talk about what is happening in that cell.\n<ol>\n  <li style=\"padding-bottom:5px;\">First, we are importing the library named `requests` which allows us to retrieve data over the web.  This is not built into the core of Python, so it's a separate library.  However, since it's one that's commonly used, Databricks has it in your cluster already.  If this was a less commonly used library, you would need to first load the library on your cluster.</li>\n  \n  <li style=\"padding-bottom:5px;\">We define a few variables, such as the part of the URL that's the same for all files located on AWS, where we will be downloading the data from.</li>\n\n  <li style=\"padding-bottom:5px;\">To make the process easier to understand, we break it into steps that can be defined as separate functions.  Each function is defined starting with `def` and the indenting in Python tells it when each function has ended.  The main code near the end of the cell is less than 10 lines long and calls the functions defined above.</li>\n\n  <li style=\"padding-bottom:5px;\">One of the first functions called is `get_manifest`, which is passed the URL you entered for the widget at the top of the notebook, it tries to download the manifest from that URL, and the manifest says what files are being downloaded.  The manifest is a tiny JSON file that we store out at a public URL and that file is a JSON object containing a name:value pair with the id for the bucket where the data is stored, and two name:value pairs with arrays as the values:\n    <ul>\n      <li style=\"padding-bottom:3px;\">An array of the files or directories that will be created in the directory where we download the data.</li>\n      <li style=\"padding-bottom:3px;\">The second array contains a JSON object for each download file with:\n        <ol>\n          <li>The name of the file being downloaded</li>\n          <li>The MD5 sum of the file. The MD5 sum is a hash of the file contents that returns a string - this is used to make sure the file downloaded is complete.</li>\n          <li>A flag indicating if the downladed file should be unzipped.  The review and user downloads are zipped files containing a directory of files.</li>\n        </ol>\n      </li>\n    </ul>\n  </li>\n  <li style=\"padding-bottom:5px;\">The code cycles through downloading and unzipping the files (as needed), and in our case the user and review files contain a directory of files compressed using the bzip2 format which Spark can load.  As each file is downloaded, the MD5 sum of the file is calculated and compared to the MD5 sum in the manifest to make sure the download is complete and data is not missing.</li>\n</ol>  \n\nWhen downloading the data, we cannot work directly in DBFS, so we download and unzip the data using the driver node and then movng the data to DBFS.  Keep in mind that where we download the files\non the file system local to the driver node of the cluster disappears when the cluster terminates, but the files we move to DBFS are permanent and will be there again when you start a new cluster."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d118f5b7-ca8e-4ace-b1f7-17a5a3a8a93d"}}},{"cell_type":"code","source":["import pyspark.sql.functions as f\nimport requests\nimport re\nimport tarfile\nimport zipfile\nimport json\nimport hashlib\n\nFORCE_DOWNLOAD = False\n\nURL_HOST = \".s3-us-west-2.amazonaws.com/\"\nTEMP_DIR = \"/yelptemp/\"\nZIPPED_DIR = \"/yelptemp/zipped/\"\nUNZIPPED_DIR = \"/yelptemp/unzipped/\"\nDATA_DIR = \"/yelp\"\n\ndef clean_all():\n  ' Removes the data directory if it exists on DBFS'\n  try:\n    dbutils.fs.rm(DATA_DIR,recurse=True)\n  except Exception:\n    pass\n  \n\ndef get_manifest():\n  ''' Returns the dictionary that's the download manifest based on the URL\n      entered in the URL widget.\n      If it's not a valid URL or returns a status code other than 200, an exception is raised.\n      If the manifest is not valid JSON, or does not contain name:value pairs named\n      id, data_list, and download_list, an exception is raised.  \n  ''' \n  manifest_url = dbutils.widgets.get(\"manifest_url\")\n  response = requests.get(manifest_url)\n  if response.status_code != 200:\n    raise Exception(f\"The manifest URL {manifest_url} returned a status of \" + str(response.status))\n  manifest = response.text\n  try:\n    manifest_dict = json.loads(manifest)\n    # The manifest should have a data_list element and a down_Load list element\n    if \"data_list\" in manifest_dict == False:\n      raise Exception(\"The manifest does not contain a data_list.\")\n    if \"download_list\" in manifest_dict == False:\n      raise Exception(\"The manifest does not contain a download_list.\")\n    return(manifest_dict)\n  except json.JSONDecodeError as err:\n    raise Exception(\"The manifest is not a valid JSON document.\", err)\n    \n\ndef check_data(manifest):\n  ''' Function used to check if the data directory contains valid\n      copies of all of the files in the download. The manifest dictionary\n      is passed as a parameter and is expected to comtain a data_list containing\n      the names of each file expected in the data directory.\n      If a file is missing, this method returns False.\n      If all of the files exist, it returns True.\n  '''\n  try:\n    data_dir_list = dbutils.fs.ls(DATA_DIR)\n    if len(db_dir_list) == 0:\n      return(False)\n      file_list = manifest[\"file_list\"]\n      existing_list = dbutils.fs.ls(DATA_DIR)\n      for file_name in file_list:\n        found == False\n        for info in existing_list:\n          if info.name == file_name:\n            found == True\n            break\n        if found == False:\n          return(False)\n      # looped through all of the required files and they are there\n      return(True)\n  except Exception:\n    # The directory does not exist, does not match the manifest, or the hashes don't match\n    return(False)\n  \ndef get_bucket_id(manifest):\n  ''' The manifest is expected to contain a name:value pair named id\n      where the value is the bucket name on S3 where the files are\n      staged.  If the id is missing or is a blanks string, then an\n      exception is raised, otherwise the bucket id is returned.\n  '''\n  try:\n    bucket = manifest['id'].strip()\n    if len(bucket) == 0:\n      raise Exception(\"The id provided in the manifest was an empty string, but should be the name of the bucket being downloaded from.\")\n    else:\n      return(bucket)\n  except Exception as e:\n    raise Exception(\"An error occurred in retrieving the bucket id from the manifest\", e)\n      \n  \ndef download_file(manifest_item, bucket_id):\n  ''' Given a dictionary from the download list, download the file to the\n      temporary directory for downloading the file and check the\n      MD5 sum to make sure it matches.\n      If the MD5 sum does not match, an excetion is raised, otherwise it prints\n      that the file was successfully downloaded.\n  '''\n  file_name = manifest_item[\"name\"]\n  item_md5sum = manifest_item[\"md5\"]\n  request_url = \"https://\" + bucket_id + URL_HOST + file_name\n  local_name = ZIPPED_DIR + file_name \n  print(\"requesting file from:\", request_url)\n  r = requests.get(request_url, stream=True)\n  status_code = r.status_code\n  # If the status code is 200, then we successfully retrieved the file\n  if status_code != 200:\n    raise Exception(f\"The {file_name} download failed. A status code of {str(status_code)} was returned from the URL:{request_url}.\")\n  else: # write the file \n    with open(local_name, 'wb') as file:\n      for chunk in r.iter_content(chunk_size=4096):\n        file.write(chunk)\n        file.flush()\n    file.close()\n  #check if the hash of the file downloaded matches the md5 sum in the manifest\n  with open(local_name, 'rb') as data_file:\n    md5sum = hashlib.md5( data_file.read() ).hexdigest()\n    if md5sum.lower() != item_md5sum.lower():\n      raise Exception(f\"The file {file_name} downloaded from Google Drive generated a MD5 sum of {md5sum} instead of the MD5 sum in the manifest ({item_md5sum}) so it may be corrupted and the processing was terminated.\")\n    else:\n      print (\"successfully downloaded:\", file_name)\n\n      \ndef process_file(manifest_item):\n    ''' The file is now downloaded.  If the file is zipped,\n        it first needs to be unziiped, and either way, moved\n        to the DBFS data directory.\n    '''\n    local_name = ZIPPED_DIR + manifest_item[\"name\"]\n    local_path = \"file:\" + local_name\n    is_zipped = manifest_item[\"zipped\"] == \"true\" # This is either Ture or False\n    if is_zipped:\n      with zipfile.ZipFile(local_name,\"r\") as zip_ref:\n        zip_ref.extractall(UNZIPPED_DIR)\n      untar_info = dbutils.fs.ls(\"file:\" + UNZIPPED_DIR)\n      # The zip file could contain a directory, a file, or more than 1 file,\n      # so we loop through the file list, moving all of them to DBFS\n      for info in untar_info:\n        destination = DATA_DIR + \"/\" + info.name\n        dbutils.fs.mv(info.path, destination, recurse=True)  \n      dbutils.fs.rm(local_path)\n    else: # file was not zipped (or should remain zipped), so just move it\n        destination = DATA_DIR + \"/\" + manifest_item[\"name\"]\n        dbutils.fs.mv(local_path, destination)  \n    print (\"processed:\", local_name)\n    \n                      \ndef load_data(manifest_list, bucket_id):\n  ''' Loops through the files in the download list from the manifest and \n      downloads the file, verifies the MD5 sum is correct, unzips it if needed,  \n      and moves the file or folder that was in it to the data directory.'''\n  # Create the empty temporary directories\n  try:\n    dbutils.fs.rm(\"file:\" + TEMP_DIR,recurse=True)\n  except Exception:\n    pass\n  # Create the temporary local directory and sub-directories\n  dbutils.fs.mkdirs(\"file:\" + TEMP_DIR)\n  dbutils.fs.mkdirs(\"file:\" + ZIPPED_DIR)\n  dbutils.fs.mkdirs(\"file:\" + UNZIPPED_DIR)\n  # Loop through the files to download\n  for item in manifest_list:\n    download_file(item, bucket_id)\n    process_file(item)\n  # Remove the temp directory used to unzip the files\n  dbutils.fs.rm(\"file:\" + TEMP_DIR, recurse=True)\n  \n  \n# *******************************************  \n# Run the Actual Routine to Load the Data\n# This code uses the above defined functions\n# *******************************************\nif FORCE_DOWNLOAD == True:\n  clean_all()\nmanifest_dict = get_manifest()\nif check_data(manifest_dict) == False:\n  bucket_id = get_bucket_id(manifest_dict)\n  download_list = manifest_dict[\"download_list\"]\n  load_data(download_list, bucket_id)\nelse:\n  print(\"All of the required files exist in the data directory already, so the download was not processed.\")\nprint(\"Done\")\n  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"319fca6a-ed9a-41dc-b655-c765bcff85b7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"name":"workshop_master","notebookId":"823144322187040","application/vnd.databricks.v1+notebook":{"notebookName":"Working With Files - Part 1 - Step 5","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2222704103242906}},"nbformat":4,"nbformat_minor":0}
